{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "12347f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Check if variables are loaded\n",
    "groq_key = os.getenv('GROQ_API_KEY')\n",
    "langchain_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "if not groq_key or not langchain_key:\n",
    "    raise ValueError(\"Missing required environment variables in .env file\")\n",
    "os.environ['GROQ_API_KEY'] = groq_key\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4694f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "LLM=ChatGroq(model='llama-3.1-8b-instant',temperature=0.7, max_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa0f70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Genai Application\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fceb5bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'title': 'LangChain overview - Docs by LangChain', 'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves', 'language': 'en'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Webdata=WebBaseLoader(\"https://docs.langchain.com/oss/python/langchain/overview\")\n",
    "docs = Webdata.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "709dee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d88189ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'title': 'LangChain overview - Docs by LangChain', 'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves', 'language': 'en'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4970bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf1e044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "db=Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42ffb2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'language': 'en', 'title': 'LangChain overview - Docs by LangChain', 'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves', 'language': 'en', 'title': 'LangChain overview - Docs by LangChain'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"What is LangChain?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e8ba2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Turing test can provide some evidence of intelligence, but it penalizes non-human intelligent behavior.[401]\\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making \\'machines that fly so exactly like pigeons that they can fool other pigeons.\\'\"[402] AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".[403]\\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".[404] Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".[405] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine – and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google,[406] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\nAs a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself[407] including discussing the many AI narratives and myths to be found within societal, political and academic discourses.[408] Similarly, in practice, some authors have suggested that the term \\'AI\\' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,[409] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".[410]\\nThere has been debate over whether large language models exhibit genuine intelligence or merely simulate it by imitating human text.[411]\\n\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\\n\\nSymbolic AI and its limits\\nSymbolic AI (or \"GOFAI\")[413] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"[414]\\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec\\'s paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.[415] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.[416] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.[ab][16]\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[418][419] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\nNeat vs. scruffy\\nMain article: Neats and scruffies\\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,[420] but eventually was seen as irrelevant. Modern AI has elements of both.\\n\\nSoft vs. hard computing\\nMain article: Soft computing\\nFinding a provably correct or optimal solution is intractable for many important problems.[15] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\n\\nNarrow vs. general AI\\nMain articles: Weak artificial intelligence and Artificial general intelligence\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field\\'s long-term goals.[421][422] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\\n\\nMachine consciousness, sentience, and mind\\nMain articles: Philosophy of artificial intelligence and Artificial consciousness\\nThere is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"[423] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\n\\nConsciousness\\nMain articles: Hard problem of consciousness and Theory of mind\\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[424] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett\\'s consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[425]\\n\\nComputationalism and functionalism\\nMain articles: Computational theory of mind and Functionalism (philosophy of mind)\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[426]\\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[ac] Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.[430]'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query from vector store db\n",
    "query=\"Explain Artificial Intelligence in simple terms\"\n",
    "result=db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c327a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrival chain, Document chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the following question based on the provided context.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(LLM,prompt=prompt) #Create docuemnt chain where we pass multiple document\n",
    "#We combine all document DOC1+DOC2+DOC3+LLM-->Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7dfe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document must come from retrival\n",
    "retriever=db.as_retriever(search_kwargs={\"k\": 3})\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1644ee1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, I will answer your question to the best of my abilities.\\n\\nWhat is LangChain and its benefits?\\n\\nLangChain is an open-source framework with a pre-built agent architecture and integrations for any model or tool, allowing you to build agents that adapt as fast as the ecosystem evolves. It provides a standard model interface, making it easy to swap providers and avoid lock-in. LangChain is the easiest way to start building agents and applications powered by LLMs, with under 10 lines of code.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=retrieval_chain.invoke({\"input\": \"Explain langchain ?\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac8dd642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Explain langchain ?',\n",
       " 'context': [Document(metadata={'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves', 'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'title': 'LangChain overview - Docs by LangChain', 'language': 'en'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by'),\n",
       "  Document(metadata={'language': 'en', 'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves', 'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'title': 'LangChain overview - Docs by LangChain'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by'),\n",
       "  Document(metadata={'title': 'LangChain overview - Docs by LangChain', 'language': 'en', 'description': 'LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolves', 'source': 'https://docs.langchain.com/oss/python/langchain/overview'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KSupportGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent core benefitsLangChain overviewCopy pageLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool — so you can build agents that adapt as fast as the ecosystem evolvesCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by')],\n",
       " 'answer': 'Based on the provided context, I will answer your question to the best of my abilities.\\n\\nWhat is LangChain and its benefits?\\n\\nLangChain is an open-source framework with a pre-built agent architecture and integrations for any model or tool, allowing you to build agents that adapt as fast as the ecosystem evolves. It provides a standard model interface, making it easy to swap providers and avoid lock-in. LangChain is the easiest way to start building agents and applications powered by LLMs, with under 10 lines of code.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b7421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gen-Agent-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
